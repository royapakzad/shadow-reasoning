{
  "name": "llm-safety-lab",
  "version": "1.0.0",
  "private": true,
  "description": "An application to evaluate and compare Large Language Models (LLMs) on both multilingual consistency and the impact of internal reasoning on safety and accuracy.",
  "scripts": {
    "build": "node create-env.js && tailwindcss -i ./src/input.css -o ./output.css",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "devDependencies": {
    "@tailwindcss/forms": "^0.5.7",
    "@tailwindcss/typography": "^0.5.13",
    "tailwindcss": "^3.4.4"
  }
}
